{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `verbose` flag is specified here, if enabled more information is printed showing what is being changed, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all required libraries here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing, import all the data from the `.boris` file, and print out how many observations are in the file, as a sanity check that all is as expected with the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 327 observations with 19911 events in total\n"
     ]
    }
   ],
   "source": [
    "intruder_test = 'intruder test_noid.boris'\n",
    "all_accurrance = 'all accurrence observations.boris'\n",
    "\n",
    "import json\n",
    "with open(intruder_test, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    original_observations = data['observations']\n",
    "    num_events = 0\n",
    "    for _,v in original_observations.items():\n",
    "        num_events = num_events + len(v['events'])\n",
    "    print(f'Have {len(original_observations)} observations with {num_events} events in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class to represent the events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event:\n",
    "    __slots__ = 'timestamp', 'subject', 'type', 'recipient'\n",
    "\n",
    "    def __init__(self, src):\n",
    "        self.timestamp = src[0]\n",
    "        self.subject = src[1]\n",
    "        self.type = src[2]\n",
    "        self.recipient = src[3]\n",
    "        \n",
    "        # mwr without a recipient is always with the partner\n",
    "        if self.type == 'mwr' and not self.recipient:\n",
    "            self.recipient = 'partner'\n",
    "                \n",
    "        assert self.timestamp >= 0, self\n",
    "        # TODO allow empty subject for the moment\n",
    "        assert any(self.subject == x for x in ['m', 'f', 'nm', 'nf', '']) or self.type == 'vstart', self\n",
    "        assert any(self.type == x for x in ['app', 'fsp', 'vstart', 'mwr', 'sb', 'pre-agg']), self\n",
    "        # TODO allow empty recipient\n",
    "        assert any(self.recipient == x for x in ['neighbour', 'intruder', 'partner', '']), self\n",
    "        \n",
    "    def __format__(self, format_spec):\n",
    "        return f'\"{self.timestamp}, {self.subject}, {self.type}, {self.recipient}\"'           \n",
    "\n",
    "    def __str__(self, format_spec):\n",
    "        return f'\"{self.timestamp}, {self.subject}, {self.type}, {self.recipient}\"'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'\"{self.timestamp}, {self.subject}, {self.type}, {self.recipient}\"'           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels on the observations must be fixed up. \"Neighbour\" to \"Experiment Control\" and \"Stranger\" to \"Experiment Treatment\", and so on.  All labels are checked against the `pattern` regular expression that is specified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\n",
    "    '(F[0-9][A-D]) +([0-9]{2})\\.([0-9]{2})\\.? ([A-D]) +(experiment|habituation) (treatment|control)')\n",
    "\n",
    "def get_label(s):\n",
    "    groups = re.fullmatch(pattern, s).groups()\n",
    "    return f'{groups[0]} 2017.{groups[2]}.{groups[1]} {groups[3]} {groups[4]} {groups[5]}'\n",
    "\n",
    "def correct_label(s):\n",
    "    new_k = str(s)\n",
    "    new_k = new_k.replace('neighbour', 'experiment control')\n",
    "    new_k = new_k.replace('stranger', 'experiment treatment')\n",
    "    new_k = new_k.replace('habituation experiment', 'habituation treatment')\n",
    "    new_k = new_k.replace('treatment control', 'experiment control')\n",
    "    new_k = new_k.replace('habitiution control', 'habituation control')\n",
    "    new_k = new_k.replace('habitiution experiment', 'habituation treatment')\n",
    "    new_k = new_k.replace('habitation experiment', 'habituation treatment')\n",
    "    new_k = new_k.replace('habitiution control', 'habituation control')\n",
    "\n",
    "    # ensure that all keys now match the expected layout\n",
    "    if not pattern.fullmatch(new_k):\n",
    "        raise ValueError()\n",
    "\n",
    "    new_k = get_label(new_k)    \n",
    "    if new_k != s:\n",
    "        if verbose:\n",
    "            print(f'Change {k:>40} -> {new_k}')\n",
    "    \n",
    "    return new_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by removing some events that are wrong/invalid.  If the vstart is missing at the start of the list of events then add it.  The events themselves are also touched up, the 'mwr' events are generally missing the recipient, and the timestamps are also normalised here such that vstart always happens at $t = 0$.  This makes the analysis further down easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation 'xxxx' is marked as invalid (starts with \"x\")\n",
      "Observation 'xxxx F5A 25.06. B habituation control' is marked as invalid (starts with \"x\")\n",
      "Observation 'xxxx F5A 25.06. A habituation control' is marked as invalid (starts with \"x\")\n",
      "Observation 'xxxx F5B 18.04. D habituation ?' is marked as invalid (starts with \"x\")\n",
      "Observation F6A 2017.04.28 B habituation control has no events!\n"
     ]
    }
   ],
   "source": [
    "observations = dict()\n",
    "\n",
    "for k,v in original_observations.items():\n",
    "    try:\n",
    "        label = correct_label(k)\n",
    "\n",
    "        events = list(map(Event, v['events']))\n",
    "\n",
    "        if not events:\n",
    "            print(f'Observation {label} has no events!')\n",
    "            continue\n",
    "\n",
    "        if events[0].type != 'vstart':\n",
    "            if verbose:\n",
    "                print(f'Observation {label} is missing a vstart as the very first event!')\n",
    "            # for the moment add a vstart with t = 0\n",
    "            events.insert(0, Event([0.0, \"\", \"vstart\", \"\", \"\"]))\n",
    "    \n",
    "        vstart_timestamp = events[0].timestamp\n",
    "        for event in events:\n",
    "            # normalise timestamps so that the vstart timestamp is always 0\n",
    "            event.timestamp = event.timestamp - vstart_timestamp\n",
    "\n",
    "        observations[label] = events\n",
    "\n",
    "    except ValueError:\n",
    "        if k.startswith('x'):\n",
    "            print(f'Observation {k!r} is marked as invalid (starts with \"x\")')\n",
    "        else:\n",
    "            print(f'Observation {k!r} is invalid?!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 320 valid observations\n"
     ]
    }
   ],
   "source": [
    "print(f'Have {len(observations)} valid observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the fun stuff really starts, so initially we have some basic scaffolding code, although with the definition of two different kinds of latency, `max_latency` and `base_latency`.  We also define a `CombiningData` type; this is the combination of the observation id plus the subject.  The output data has one row for each unique `CombiningData`.  The `get_first_occurance_timestamp` searches a list of events until both the subject and recipient are matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_latency = 1000000\n",
    "base_latency = 120\n",
    "\n",
    "class CombiningData(namedtuple('CombiningData', ['obs_id', 'subject'])):\n",
    "    def get_csv(self):\n",
    "        return '{}, {}, {}, {}, {}, {}'.format(*self.obs_id.split(' '), self.subject)\n",
    "\n",
    "def get_first_occurance_timestamp(subject, recipient, events):\n",
    "    for event in events:\n",
    "        if event.type == 'vstart':\n",
    "            continue\n",
    "        if event.recipient == recipient and event.subject == subject:\n",
    "           return event.timestamp\n",
    "    return max_latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GetLatency` class takes a list of events and determines the timestamp of the first event for each combination subject and recipient.  We are not interested in any events involving the partner, only intruder and neighbour.  If there is no event in the list for any subject and recipient pair, then insert a \"maximum latency\"; this is the lowest latency of all combinations for this list of events plus the \"base latency\", which was specified in the previous cell (`base_latency`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetLatency:\n",
    "    __slots__ = \\\n",
    "        'm_intruder', \\\n",
    "        'f_intruder', \\\n",
    "        'nm_intruder', \\\n",
    "        'nf_intruder', \\\n",
    "        'm_neighbour', \\\n",
    "        'f_neighbour', \\\n",
    "        'nm_neighbour', \\\n",
    "        'nf_neighbour'\n",
    "\n",
    "    def __init__(self, events):\n",
    "        # generate a list of the slots and get the first timestamp for each.\n",
    "        tuples = [(x, y, f'{x}_{y}') for x in ['m', 'f', 'nm', 'nf'] for y in ['intruder', 'neighbour']]\n",
    "        for t in tuples:\n",
    "            setattr(self, t[2], get_first_occurance_timestamp(t[0], t[1], events))\n",
    "\n",
    "        # now for all events in this observation calculate the minimal latency.\n",
    "        min_latency = min(map(lambda x: getattr(self, x[2]), tuples))\n",
    "\n",
    "        # check that every observation has a minimum latency\n",
    "        assert min_latency != max_latency, events\n",
    "        \n",
    "        # cap all latencies, if there is no event in this observation then\n",
    "        # get_first_occurance_timestamp returns a very large latency which is\n",
    "        # definitely going to be much much larger than base_latency plus min_latency.\n",
    "        for t in tuples:\n",
    "            setattr(self, t[2], min(base_latency + min_latency, getattr(self, t[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the scaffolding setup this is a straightforward traverse of the data generating a dictionary of `CombiningData` to latencies, called `latencies` (not very original).  For each `CombiningData` there are two latencies, the intruder latency and the neighbour latency.  So for each observation we should be entering four entries into `latencies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Latency = namedtuple('Latency', ['intruder', 'neighbour'])\n",
    "\n",
    "latencies = dict()\n",
    "\n",
    "for label, events in observations.items():\n",
    "    latency = GetLatency(events)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'{label}, m, {latency.m_intruder}, {latency.m_neighbour}')\n",
    "        print(f'{label}, f, {latency.f_intruder}, {latency.f_neighbour}')\n",
    "        print(f'{label}, nm, {latency.nm_intruder}, {latency.nm_neighbour}')\n",
    "        print(f'{label}, nf, {latency.nf_intruder}, {latency.nf_neighbour}')\n",
    "\n",
    "    # store latencies for next step\n",
    "    latencies[CombiningData(label, 'm')] = Latency(latency.m_intruder, latency.m_neighbour)\n",
    "    latencies[CombiningData(label, 'f')] = Latency(latency.f_intruder, latency.f_neighbour)\n",
    "    latencies[CombiningData(label, 'nm')] = Latency(latency.nm_intruder, latency.nm_neighbour)\n",
    "    latencies[CombiningData(label, 'nf')] = Latency(latency.nf_intruder, latency.nf_neighbour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the core of what we did in the first python script, so first up define a data structure to hold the data.  We already have the `CombiningData`, so that is the \"key\", and the output will have one row for each `CombiningData`.  The value type is the `BehaviourModifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can't be a namedTuple, as we need to update the fields using set & get attr.\n",
    "# Use slots for speed & to ensure that only the fields we want are valid.\n",
    "class BehaviourModifier:\n",
    "    __slots__ = \\\n",
    "        'app_intruder', \\\n",
    "        'app_neighbour', \\\n",
    "        'app_partner', \\\n",
    "        'fsp_intruder', \\\n",
    "        'fsp_neighbour', \\\n",
    "        'fsp_partner', \\\n",
    "        'sb_intruder', \\\n",
    "        'sb_neighbour', \\\n",
    "        'sb_partner', \\\n",
    "        'mwr_partner', \\\n",
    "        'l_intruder', \\\n",
    "        'l_neighbour'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.app_intruder = 0\n",
    "        self.app_neighbour = 0\n",
    "        self.app_partner = 0\n",
    "        self.fsp_intruder = 0\n",
    "        self.fsp_neighbour = 0\n",
    "        self.fsp_partner = 0\n",
    "        self.sb_intruder = 0\n",
    "        self.sb_neighbour = 0\n",
    "        self.sb_partner = 0\n",
    "        self.mwr_partner = 0\n",
    "        self.l_intruder = None\n",
    "        self.l_neighbour = None\n",
    "    \n",
    "    def get_csv(self):\n",
    "        return f'{self.app_intruder}, {self.app_neighbour}, {self.app_partner}, ' + \\\n",
    "            f'{self.fsp_intruder}, {self.fsp_neighbour}, {self.fsp_partner}, ' + \\\n",
    "            f'{self.sb_intruder}, {self.sb_neighbour}, {self.sb_partner}, ' + \\\n",
    "            f'{self.mwr_partner}, {self.l_intruder}, {self.l_neighbour}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the observations, then over the events, and total up how many events of each type are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing subject: \"F1B 2017.05.01 D experiment treatment\" \"63.464, , app, intruder\", skipping...\n",
      "Missing subject: \"F6A 2017.05.01 B experiment control\" \"17.959999999999997, , app, intruder\", skipping...\n",
      "Missing subject: \"F6A 2017.05.01 B experiment control\" \"78.898, , app, partner\", skipping...\n"
     ]
    }
   ],
   "source": [
    "# key is a CombiningData, value is BehaviourModifier\n",
    "combo_dict = dict()\n",
    "\n",
    "for label in observations.keys():\n",
    "    for subject in ['m', 'f', 'nm', 'nf']:\n",
    "        combo_dict[CombiningData(label, subject)] = BehaviourModifier()\n",
    "\n",
    "# iterate over the observations\n",
    "for label, events in observations.items():\n",
    "    # iterate over the events in the observation\n",
    "    for event in events:\n",
    "        if not event.subject or event.type == 'vstart':\n",
    "            if event.type != 'vstart':\n",
    "                print(f'Missing subject: \"{combo.obs_id}\" {event}, skipping...')\n",
    "            continue\n",
    "\n",
    "        combo = CombiningData(label, event.subject)\n",
    "        data = combo_dict[combo]\n",
    "\n",
    "        # now increment certain fields\n",
    "        field = f'{event.type}_{event.recipient}'\n",
    "\n",
    "        try:\n",
    "            setattr(data, field, getattr(data, field) + 1)\n",
    "\n",
    "        except AttributeError:\n",
    "            # pre-agg should just be ignored in the analysis\n",
    "            assert field == 'pre-agg_', field\n",
    "\n",
    "            # ignore errors\n",
    "            continue\n",
    "\n",
    "        combo_dict[combo] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting the latencies can be done in one place.  As both the `combo_dict` and `latencies` use the same set of keys, the lookup should never fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combo_label, item in combo_dict.items():\n",
    "    item.l_intruder = latencies[combo_label].intruder\n",
    "    item.l_neighbour = latencies[combo_label].neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: there should be $4 \\times len(observations)$ in combo data, as each observation has four subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo dict has 1280 items, should have 1280 items\n"
     ]
    }
   ],
   "source": [
    "print(f'Combo dict has {len(combo_dict)} items, should have {4 * len(observations)} items')\n",
    "assert len(combo_dict) == 4 * len(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally output the data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 123273 bytes\n"
     ]
    }
   ],
   "source": [
    "# now output the data to a csv file for further processing\n",
    "with open('output_data.csv','w') as f:\n",
    "    f.write('tank_num, date, int_pos, phase, cond, subject, app_int, app_n, app_p, fsp_int, fsp_n, fsp_p, sb_int, sb_n, sb_p, mwr_p, l_int, l_n\\n')\n",
    "    for k, v in combo_dict.items():\n",
    "        f.write(f'{k.get_csv()}, {v.get_csv()}\\n')\n",
    "\n",
    "    print(f'Wrote {f.tell()} bytes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
